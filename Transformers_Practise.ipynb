{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TVHsCn0oAsk",
        "outputId": "2652c54c-0429-4ed7-bf53-f1f34563d781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.90184977  0.15411072  0.3706254  -0.19573535 -0.20905336 -0.04206784\n",
            "   0.05644867 -1.68299375]\n",
            " [-0.41769654 -1.19041593  0.24163268  0.72984339  0.42819747 -0.10946848\n",
            "  -0.26156017 -0.60022088]\n",
            " [-0.40550481  0.36050594  0.09617871 -0.36587733  0.2692972   0.6496429\n",
            "   0.53975705 -1.35073673]\n",
            " [-1.1460233  -2.03122525  0.42927282  1.40763456  1.36883224  1.49562401\n",
            "  -0.18552601 -1.92750317]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "L, d_k, d_v = 4, 8, 8\n",
        "q = np.random.randn(L, d_k)\n",
        "k = np.random.randn(L, d_k)\n",
        "v = np.random.randn(L, d_v)\n",
        "print(q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.matmul(q, k.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnY8CzWJokOI",
        "outputId": "93f1ab18-0cc2-4ab5-efb7-2e2cb18ab5ef"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.19960643, -1.19657572, -2.42658099,  0.96070104],\n",
              "       [ 0.65068232, -0.86005545, -2.41887907, -0.42951497],\n",
              "       [-0.11240723, -0.76060531, -0.84404746,  1.29965861],\n",
              "       [-0.62761341, -3.02248007, -5.15491062,  0.54064569]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var(), k.var(), np.matmul(q, k.T).var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT04Sg-_okQ2",
        "outputId": "d4b99061-26dc-4938-d740-67eee29c8dc0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.126221119112162, 0.9905244163595975, 8.356847786707736)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Dividing by the square root of the dimension of the key vectors dk in the self-attention mechanism is a technique\n",
        " to prevent the dot product from growing too large in magnitude\"\"\"\n",
        "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
        "q.var(), k.var(), scaled.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuRL1qRCokUN",
        "outputId": "8940e9f3-8022-4ff7-e04c-18939cc23372"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7687976543737907, 1.0225989493190337, 0.3245577325617038)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbktXu6bokWi",
        "outputId": "24c0fefc-b89e-4374-baa2-afb239700bfd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.29120271,  0.19411435,  1.74576012, -1.08729967],\n",
              "       [ 0.62970807,  1.07110441,  0.21920558, -0.68585846],\n",
              "       [-0.79647138, -1.16257883, -0.66547283, -1.07039639],\n",
              "       [ 0.18926566,  0.04490585, -1.49451507,  2.12600157]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mask = np.tril(np.ones( (L, L) ))\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JpY-4tXqjlA",
        "outputId": "c538e56d-e710-4a73-9a66-efdc71218b64"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [1., 1., 0., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask[mask == 0] = -np.infty\n",
        "mask[mask == 1] = 0"
      ],
      "metadata": {
        "id": "Z-kczihEqjm1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc=scaled + mask\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLsJRXkz3H6Y",
        "outputId": "3be60374-eb04-4bcd-be84-44bc99632966"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.07057153,        -inf,        -inf,        -inf],\n",
              "       [ 0.23005094, -0.30407552,        -inf,        -inf],\n",
              "       [-0.03974196, -0.26891458, -0.29841584,        -inf],\n",
              "       [-0.22189485, -1.06860808, -1.82253613,  0.19114712]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJLXTUbl8Qpv",
        "outputId": "cfa1f19c-c811-43e1-d772-5280a3f4e9da"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.93186108, 0.        , 0.        , 0.        ],\n",
              "       [1.25866412, 0.73780515, 0.        , 0.        ],\n",
              "       [0.9610374 , 0.76420853, 0.74199272, 0.        ],\n",
              "       [0.80099959, 0.34348629, 0.16161535, 1.21063755]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(np.exp(sc), axis=-1)\n",
        "\"\"\" hen np.sum(x, axis=-1) will sum across the last axis (columns in a 2D array),\n",
        "resulting in a 1D array where each element is the sum of each row of the original array\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zoLeu3yx3IBa",
        "outputId": "09c9f78b-107a-4b6a-ccea-1c9c0ee9681f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' hen np.sum(x, axis=-1) will sum across the last axis (columns in a 2D array), \\nresulting in a 1D array where each element is the sum of each row of the original array'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
        "\n",
        "attention=softmax(sc)\n",
        "print(attention)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgwPp8Y7-Lgc",
        "outputId": "3b60a7b2-9ad1-40b5-d102-f67f40cc030f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.         0.        ]\n",
            " [0.63044503 0.36955497 0.         0.        ]\n",
            " [0.38951943 0.30974244 0.30073812 0.        ]\n",
            " [0.31826886 0.13648071 0.06421618 0.48103425]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTIHEAD ATTENTION"
      ],
      "metadata": {
        "id": "qTepQK45ETAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "SG4FaoQi-Lih"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sequence_length = 4\n",
        "batch_size = 1\n",
        "input_dim = 512\n",
        "d_model = 512\n",
        "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzy__mJg-Lny",
        "outputId": "a60c6532-9110-4250-9459-15d37c1b2020"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
        "qkv = qkv_layer(x)\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2FNtQ7o-LqA",
        "outputId": "1c9be291-8008-42f7-add0-9cc9dccdba6c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 1536])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
        "x_val = np.arange(-1, 1, 0.01) * 3\n",
        "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
        "plt.title('qkv distribution')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "1MXo-c0fE4bA",
        "outputId": "024171e7-4706-4ed0-e745-05dde77b21e8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'qkv distribution')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads = 8\n",
        "\"\"\"Since it is multihead q,k,v dim will be further divided into numod heads so 512/8=64\"\"\"\n",
        "head_dim = d_model // num_heads\n",
        "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)"
      ],
      "metadata": {
        "id": "yUYl0nDQE4dK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self-attention in a transformer allows each word in a sentence to influence the representation of every other word. For instance, in the sentence \"The animal didn't cross the street because it was too tired,\" self-attention allows the model to associate \"it\" with \"animal\" by weighting that connection more heavily. This mechanism dynamically adjusts based on context, enabling the model to understand relationships and dependencies in the data, regardless of their position in the input sequence. This is crucial for tasks requiring an understanding of context and semantics."
      ],
      "metadata": {
        "id": "7sVw8DE2GD5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ0jmz46E4gd",
        "outputId": "bddbba0d-b3e2-42cc-ed50-c4bea6755094"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 8, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
        "qkv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZr8wI4uHRIs",
        "outputId": "72174555-62e0-412e-c1e6-e2fe4f9ca714"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 192])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q, k, v = qkv.chunk(3, dim=-1)\n",
        "q.shape, k.shape, v.shape\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXvRD-tJjlO9",
        "outputId": "4590e3df-9e4b-4769-c021-c5fd3542afe4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]),\n",
              " torch.Size([1, 8, 4, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(q.shape)\n",
        "k.transpose(-2, -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw6-qIUHlIF0",
        "outputId": "8a7d45c0-ac7f-4e6a-9e56-5a7ee440b207"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 4, 64])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 64, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled.shape\n",
        "\"\"\"calculate the output dimensions of a matrix multiplication (matmul),\n",
        " follow this rule: If you multiply two matrices of dimensions (a, b) and (b, c), the resulting matrix will have dimensions (a, c).\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUnXpQAzlbr_",
        "outputId": "aa19d565-8905-41ef-f231-4f6e8991f60f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = q.size()[-1]\n",
        "print(d_k)\n",
        "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "scaled.shape\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clAFikr-jlT6",
        "outputId": "eaa83407-1dd6-4734-bb97-43ec8aa18d7f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.full(scaled.size() , float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1)\n",
        "mask[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qmQmVT2jlWf",
        "outputId": "3e600cb5-785d-44c6-e758-b0ff2077a625"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., -inf, -inf, -inf],\n",
              "        [0., 0., -inf, -inf],\n",
              "        [0., 0., 0., -inf],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(scaled + mask).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhSWYwi0mZ4c",
        "outputId": "0ae5617a-acec-47dc-dc44-258079b68348"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled += mask\n",
        "\n",
        "attention = F.softmax(scaled, dim=-1)\n",
        ""
      ],
      "metadata": {
        "id": "rgeBgw2JmZ7J"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M14vnfk9maCc",
        "outputId": "612d2afe-7201-410b-e6f1-4be8463274b2"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eDFW2Uvn3Y5",
        "outputId": "544d98a4-4204-437a-b039-ddfc390618f8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "values = torch.matmul(attention, v)\n",
        "values.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtug8PSan3bj",
        "outputId": "4140800e-aacd-42e8-f059-6b48d7e2e947"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 4, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, input_dim = x.size()\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        print(f\"values.size(): {values.size()}\")\n",
        "        out = self.linear_layer(values)\n",
        "        print(f\"out.size(): {out.size()}\")\n",
        "        return out\n",
        "\n"
      ],
      "metadata": {
        "id": "MkQLcuw3qAVh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 1024\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "\n",
        "batch_size = 30\n",
        "sequence_length = 5\n",
        "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
        "\n",
        "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
        "out = model.forward(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QvzL2S3qAXz",
        "outputId": "5c338145-cb7a-4e37-eb48-e4ac167e2343"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.size(): torch.Size([30, 5, 1024])\n",
            "qkv.size(): torch.Size([30, 5, 1536])\n",
            "qkv.size(): torch.Size([30, 5, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 5, 192])\n",
            "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
            "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
            "values.size(): torch.Size([30, 5, 512])\n",
            "out.size(): torch.Size([30, 5, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional encoding"
      ],
      "metadata": {
        "id": "qNI7njAnsahq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "max_sequence_length = 10\n",
        "d_model = 6"
      ],
      "metadata": {
        "id": "tSgQYJ0zsd9O"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "even_i = torch.arange(0, d_model, 2).float()\n",
        "print(even_i)\n",
        "even_denominator = torch.pow(10000, even_i/d_model)\n",
        "print(even_denominator)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b52iQTesfJi",
        "outputId": "c40ae89b-1d09-4ca9-9f64-241281992777"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 2., 4.])\n",
            "tensor([  1.0000,  21.5443, 464.1590])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_i = torch.arange(1, d_model, 2).float()\n",
        "even_denominator = torch.pow(10000, (odd_i - 1)/d_model)\n",
        "even_denominator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "repI4-LKsfL6",
        "outputId": "822fbd36-aea0-45e9-9237-1631980fc0e4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1.0000,  21.5443, 464.1590])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "denominator = even_denominator\n",
        "position = torch.arange(max_sequence_length, dtype=torch.float).reshape(max_sequence_length, 1)\n",
        "position"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L13n5jnJsfOp",
        "outputId": "1939f32a-c68b-4ef7-9a29-deead7d4cd6b"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.],\n",
              "        [6.],\n",
              "        [7.],\n",
              "        [8.],\n",
              "        [9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "even_PE = torch.sin(position / denominator)\n",
        "odd_PE = torch.cos(position / denominator)\n",
        "print(even_PE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlAvMbsPsfRD",
        "outputId": "3e6f6961-31f8-469a-d601-5a025d1b61e9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000],\n",
            "        [ 0.8415,  0.0464,  0.0022],\n",
            "        [ 0.9093,  0.0927,  0.0043],\n",
            "        [ 0.1411,  0.1388,  0.0065],\n",
            "        [-0.7568,  0.1846,  0.0086],\n",
            "        [-0.9589,  0.2300,  0.0108],\n",
            "        [-0.2794,  0.2749,  0.0129],\n",
            "        [ 0.6570,  0.3192,  0.0151],\n",
            "        [ 0.9894,  0.3629,  0.0172],\n",
            "        [ 0.4121,  0.4057,  0.0194]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "odd_PE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxLWHcZ4trRl",
        "outputId": "12ea99ff-9f2b-41d9-966f-553839ac5fce"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0000,  1.0000,  1.0000],\n",
              "        [ 0.5403,  0.9989,  1.0000],\n",
              "        [-0.4161,  0.9957,  1.0000],\n",
              "        [-0.9900,  0.9903,  1.0000],\n",
              "        [-0.6536,  0.9828,  1.0000],\n",
              "        [ 0.2837,  0.9732,  0.9999],\n",
              "        [ 0.9602,  0.9615,  0.9999],\n",
              "        [ 0.7539,  0.9477,  0.9999],\n",
              "        [-0.1455,  0.9318,  0.9999],\n",
              "        [-0.9111,  0.9140,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "stacked.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgvR9x_trUF",
        "outputId": "ee04c777-0aae-4696-9a78-c4d8738033f2"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzzJzCIXtrXO",
        "outputId": "b804633c-73dd-401c-8a4f-7493e8cd1cbc"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000],\n",
              "         [ 0.0000,  1.0000]],\n",
              "\n",
              "        [[ 0.8415,  0.5403],\n",
              "         [ 0.0464,  0.9989],\n",
              "         [ 0.0022,  1.0000]],\n",
              "\n",
              "        [[ 0.9093, -0.4161],\n",
              "         [ 0.0927,  0.9957],\n",
              "         [ 0.0043,  1.0000]],\n",
              "\n",
              "        [[ 0.1411, -0.9900],\n",
              "         [ 0.1388,  0.9903],\n",
              "         [ 0.0065,  1.0000]],\n",
              "\n",
              "        [[-0.7568, -0.6536],\n",
              "         [ 0.1846,  0.9828],\n",
              "         [ 0.0086,  1.0000]],\n",
              "\n",
              "        [[-0.9589,  0.2837],\n",
              "         [ 0.2300,  0.9732],\n",
              "         [ 0.0108,  0.9999]],\n",
              "\n",
              "        [[-0.2794,  0.9602],\n",
              "         [ 0.2749,  0.9615],\n",
              "         [ 0.0129,  0.9999]],\n",
              "\n",
              "        [[ 0.6570,  0.7539],\n",
              "         [ 0.3192,  0.9477],\n",
              "         [ 0.0151,  0.9999]],\n",
              "\n",
              "        [[ 0.9894, -0.1455],\n",
              "         [ 0.3629,  0.9318],\n",
              "         [ 0.0172,  0.9999]],\n",
              "\n",
              "        [[ 0.4121, -0.9111],\n",
              "         [ 0.4057,  0.9140],\n",
              "         [ 0.0194,  0.9998]]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.flatten(stacked, start_dim=1, end_dim=2) flattens the tensor stacked starting from start_dim=1 to end_dim=2. This means it collapses the second and third dimensions of the tensor into a single dimension, effectively transforming a tensor of shape (n, m, 2) into shape (n, m*2)"
      ],
      "metadata": {
        "id": "rjE8JWFPxKAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "PE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R08ujkBZubG0",
        "outputId": "ddbe2db9-d3d5-42ed-aa3a-ebf49ccf0d74"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
              "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
              "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
              "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
              "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
              "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
              "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
              "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
              "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer Normalization"
      ],
      "metadata": {
        "id": "zUTrSjr1Tbd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "eMHjV9UzubJO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])\n",
        "B, S, E = inputs.size()\n",
        "inputs = inputs.reshape(S, B, E)\n",
        "inputs.size()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvld4YccubLx",
        "outputId": "65602afb-9814-413d-aed9-514eece99c66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parameter_shape = inputs.size()[-2:]\n",
        "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
        "beta =  nn.Parameter(torch.zeros(parameter_shape))"
      ],
      "metadata": {
        "id": "vGI1mdfgubOc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gamma.size(), beta.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFVTcxm0ubQ6",
        "outputId": "4bef9c35-9f04-4b7f-9e75-8d90ba35f3b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 3]), torch.Size([1, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(parameter_shape))\n",
        "dims = [-(i + 1) for i in range(len(parameter_shape))]\n",
        "print(dims) #need to apply layer normalization on last 2 layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exMNTEuBTq1D",
        "outputId": "33821886-3844-480f-c757-fd94261c1023"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "[-1, -2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.shape)\n",
        "mean = inputs.mean(dim=dims, keepdim=True)\n",
        "mean.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR1-jlMMf7lQ",
        "outputId": "b980919d-97d4-47db-bec6-c02d869a67f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 3])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_test = torch.Tensor([[[[0.2, 0.1, 0.3],[0.2, 0.5, 0.3]], [[0.5, 0.1, 0.1],[0.5, 0.9, 0.1]]]])\n",
        "print(inputs_test.shape)\n",
        "mean = inputs_test.mean(dim=dims, keepdim=True)\n",
        "print(mean)\n",
        "mean.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z51Sldj2Tq3a",
        "outputId": "729e5f9a-8343-4467-92df-4a148605f69b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 2, 3])\n",
            "tensor([[[[0.2667]],\n",
            "\n",
            "         [[0.3667]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean\",inputs - mean)\n",
        "var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "print(\"var\",var,var.shape)\n",
        "epsilon = 1e-5\n",
        "std = (var + epsilon).sqrt()\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEJw_vJXTq6e",
        "outputId": "2a2efee3-f1a6-467d-fce3-0d5264bbc0b8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean tensor([[[ 0.0000, -0.1000,  0.1000]],\n",
            "\n",
            "        [[ 0.2667, -0.1333, -0.1333]]])\n",
            "var tensor([[[0.0067]],\n",
            "\n",
            "        [[0.0356]]]) torch.Size([2, 1, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0817]],\n",
              "\n",
              "        [[0.1886]]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = (inputs - mean) / std\n",
        "print(y,y.shape)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lc1F0w2Tq9A",
        "outputId": "a09c1c25-70c1-4af7-ef6b-91a8bcf52752"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
            "\n",
            "        [[ 1.4140, -0.7070, -0.7070]]]) torch.Size([2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape,gamma.shape)\n",
        "out = gamma * y + beta\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ZAk_MkgmYI",
        "outputId": "08b67625-2516-4946-fd94-3b0085ff5702"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1, 3]) torch.Size([1, 3])\n",
            "tensor([[[ 0.0000, -1.2238,  1.2238]],\n",
            "\n",
            "        [[ 1.4140, -0.7070, -0.7070]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output tensor you're seeing with a grad_fn component indicates that this tensor is part of PyTorch's autograd system, which automatically tracks operations on tensors for which gradients may need to be calculated. This is typical for tensors that result from operations on tensors with requires_grad=True,\n",
        "Since gamma and beta is consider as trainalbe parameter automatically"
      ],
      "metadata": {
        "id": "4iv-QE8QiR1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LayerNormalization():\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "        print(self.gamma.shape)\n",
        "\n",
        "    def forward(self, input):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        print(\"Dims\",dims)\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
        "        return out"
      ],
      "metadata": {
        "id": "5Pj0ZrrtiRma"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "sentence_length = 5\n",
        "embedding_dim = 8\n",
        "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
        "\n",
        "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3YHelDVgma2",
        "outputId": "183ba20f-b791-48d1-c531-3cb3f95675c5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[-0.1772, -0.8778, -0.2209, -0.2623,  0.2507, -0.2624,  0.1441,\n",
            "          -0.8016],\n",
            "         [-1.1089,  0.0484, -0.7263, -0.5982, -1.4576,  0.9606,  0.3574,\n",
            "           0.1240],\n",
            "         [-1.4296,  1.9855, -2.1145, -1.0625, -1.1589, -1.2160, -1.7107,\n",
            "           1.6340]],\n",
            "\n",
            "        [[-0.3196,  0.3523, -0.3200,  0.1945, -0.3626,  0.7313, -1.7217,\n",
            "          -1.2250],\n",
            "         [-0.4733,  0.0865,  0.0667,  1.9651,  0.1626,  0.8184, -1.1543,\n",
            "           1.2310],\n",
            "         [-0.6515,  0.8125, -1.1692, -0.0534, -1.5445,  0.2102, -2.1683,\n",
            "           0.2088]],\n",
            "\n",
            "        [[-0.6443,  1.3153, -0.5172,  2.0981,  1.4767, -1.2782,  1.6193,\n",
            "           0.4117],\n",
            "         [ 0.4125,  0.0935, -0.6681, -0.0903,  0.0721,  1.4806, -0.6909,\n",
            "           0.8981],\n",
            "         [-0.1701, -0.7780, -1.7566, -0.1337, -0.2035,  1.1230, -1.5906,\n",
            "          -2.0821]],\n",
            "\n",
            "        [[ 1.1599, -0.0198,  0.1793,  0.0742,  0.5565, -0.5228, -0.2151,\n",
            "          -1.3535],\n",
            "         [ 1.9157,  0.6849, -0.3612,  0.2305,  1.5884, -0.1296,  0.0953,\n",
            "          -0.9061],\n",
            "         [-0.0443,  0.2302,  0.4174, -0.2474,  2.0349,  0.3431, -0.9959,\n",
            "           1.1895]],\n",
            "\n",
            "        [[ 0.9003,  0.8015,  0.5490, -1.2109,  0.6620, -1.4833, -0.5872,\n",
            "          -0.2237],\n",
            "         [ 1.3181, -0.6192,  0.9716,  0.8615,  0.4318, -0.5165,  0.7334,\n",
            "           0.5277],\n",
            "         [-0.1401, -1.2218, -0.6701, -2.1516,  0.2306, -0.8548, -1.3751,\n",
            "          -1.8577]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.size()[-1])\n",
        "layer_norm = LayerNormalization(inputs.size()[-1:])\n",
        "print(layer_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jg2TxC_ixId",
        "outputId": "f36ce427-9548-45ca-a596-7b38510e0c83"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "torch.Size([8])\n",
            "<__main__.LayerNormalization object at 0x7d27233b2740>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = layer_norm.forward(inputs)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNzzsuo8ixLJ",
        "outputId": "144bbb7f-c385-41fb-e7f5-e796bca5bd18"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dims [-1]\n",
            "Mean \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[-0.2759],\n",
            "         [-0.3001],\n",
            "         [-0.6341]],\n",
            "\n",
            "        [[-0.3339],\n",
            "         [ 0.3379],\n",
            "         [-0.5444]],\n",
            "\n",
            "        [[ 0.5602],\n",
            "         [ 0.1884],\n",
            "         [-0.6990]],\n",
            "\n",
            "        [[-0.0177],\n",
            "         [ 0.3897],\n",
            "         [ 0.3659]],\n",
            "\n",
            "        [[-0.0740],\n",
            "         [ 0.4636],\n",
            "         [-1.0051]]])\n",
            "Standard Deviation \n",
            " (torch.Size([5, 3, 1])): \n",
            " tensor([[[0.3718],\n",
            "         [0.7573],\n",
            "         [1.4486]],\n",
            "\n",
            "        [[0.7588],\n",
            "         [0.9171],\n",
            "         [0.9525]],\n",
            "\n",
            "        [[1.1678],\n",
            "         [0.6920],\n",
            "         [0.9998]],\n",
            "\n",
            "        [[0.6930],\n",
            "         [0.8998],\n",
            "         [0.8577]],\n",
            "\n",
            "        [[0.8811],\n",
            "         [0.6478],\n",
            "         [0.7612]]])\n",
            "y \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[ 0.2655, -1.6190,  0.1479,  0.0367,  1.4167,  0.0364,  1.1299,\n",
            "          -1.4141],\n",
            "         [-1.0680,  0.4601, -0.5629, -0.3937, -1.5286,  1.6648,  0.8683,\n",
            "           0.5600],\n",
            "         [-0.5491,  1.8083, -1.0220, -0.2958, -0.3623, -0.4017, -0.7432,\n",
            "           1.5657]],\n",
            "\n",
            "        [[ 0.0187,  0.9043,  0.0183,  0.6963, -0.0379,  1.4037, -1.8290,\n",
            "          -1.1744],\n",
            "         [-0.8845, -0.2740, -0.2956,  1.7743, -0.1911,  0.5240, -1.6270,\n",
            "           0.9739],\n",
            "         [-0.1124,  1.4246, -0.6559,  0.5155, -1.0500,  0.7922, -1.7048,\n",
            "           0.7908]],\n",
            "\n",
            "        [[-1.0314,  0.6466, -0.9225,  1.3169,  0.7848, -1.5742,  0.9069,\n",
            "          -0.1271],\n",
            "         [ 0.3238, -0.1372, -1.2379, -0.4028, -0.1681,  1.8673, -1.2707,\n",
            "           1.0256],\n",
            "         [ 0.5289, -0.0790, -1.0578,  0.5653,  0.4955,  1.8223, -0.8918,\n",
            "          -1.3834]],\n",
            "\n",
            "        [[ 1.6992, -0.0031,  0.2843,  0.1325,  0.8285, -0.7289, -0.2849,\n",
            "          -1.9275],\n",
            "         [ 1.6958,  0.3280, -0.8345, -0.1770,  1.3321, -0.5772, -0.3272,\n",
            "          -1.4401],\n",
            "         [-0.4784, -0.1583,  0.0600, -0.7151,  1.9460, -0.0266, -1.5879,\n",
            "           0.9602]],\n",
            "\n",
            "        [[ 1.1058,  0.9937,  0.7072, -1.2903,  0.8354, -1.5995, -0.5824,\n",
            "          -0.1698],\n",
            "         [ 1.3190, -1.6713,  0.7843,  0.6142, -0.0490, -1.5128,  0.4166,\n",
            "           0.0990],\n",
            "         [ 1.1363, -0.2847,  0.4401, -1.5062,  1.6233,  0.1974, -0.4861,\n",
            "          -1.1202]]])\n",
            "out \n",
            " (torch.Size([5, 3, 8])) = \n",
            " tensor([[[ 0.2655, -1.6190,  0.1479,  0.0367,  1.4167,  0.0364,  1.1299,\n",
            "          -1.4141],\n",
            "         [-1.0680,  0.4601, -0.5629, -0.3937, -1.5286,  1.6648,  0.8683,\n",
            "           0.5600],\n",
            "         [-0.5491,  1.8083, -1.0220, -0.2958, -0.3623, -0.4017, -0.7432,\n",
            "           1.5657]],\n",
            "\n",
            "        [[ 0.0187,  0.9043,  0.0183,  0.6963, -0.0379,  1.4037, -1.8290,\n",
            "          -1.1744],\n",
            "         [-0.8845, -0.2740, -0.2956,  1.7743, -0.1911,  0.5240, -1.6270,\n",
            "           0.9739],\n",
            "         [-0.1124,  1.4246, -0.6559,  0.5155, -1.0500,  0.7922, -1.7048,\n",
            "           0.7908]],\n",
            "\n",
            "        [[-1.0314,  0.6466, -0.9225,  1.3169,  0.7848, -1.5742,  0.9069,\n",
            "          -0.1271],\n",
            "         [ 0.3238, -0.1372, -1.2379, -0.4028, -0.1681,  1.8673, -1.2707,\n",
            "           1.0256],\n",
            "         [ 0.5289, -0.0790, -1.0578,  0.5653,  0.4955,  1.8223, -0.8918,\n",
            "          -1.3834]],\n",
            "\n",
            "        [[ 1.6992, -0.0031,  0.2843,  0.1325,  0.8285, -0.7289, -0.2849,\n",
            "          -1.9275],\n",
            "         [ 1.6958,  0.3280, -0.8345, -0.1770,  1.3321, -0.5772, -0.3272,\n",
            "          -1.4401],\n",
            "         [-0.4784, -0.1583,  0.0600, -0.7151,  1.9460, -0.0266, -1.5879,\n",
            "           0.9602]],\n",
            "\n",
            "        [[ 1.1058,  0.9937,  0.7072, -1.2903,  0.8354, -1.5995, -0.5824,\n",
            "          -0.1698],\n",
            "         [ 1.3190, -1.6713,  0.7843,  0.6142, -0.0490, -1.5128,  0.4166,\n",
            "           0.0990],\n",
            "         [ 1.1363, -0.2847,  0.4401, -1.5062,  1.6233,  0.1974, -0.4861,\n",
            "          -1.1202]]], grad_fn=<AddBackward0>)\n",
            "torch.Size([5, 3, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORMER OVERALL STRUCTURE"
      ],
      "metadata": {
        "id": "lKimszmMxOn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    print(f\"scaled.size() : {scaled.size()}\")\n",
        "    if mask is not None:\n",
        "        print(f\"-- ADDING MASK of shape {mask.size()} --\")\n",
        "        # Broadcasting add. So just the last N dimensions need to match\n",
        "        scaled += mask\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, max_sequence_length, d_model = x.size()\n",
        "        print(f\"x.size(): {x.size()}\") #30x200x512\n",
        "        qkv = self.qkv_layer(x)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, max_sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
        "        values = values.reshape(batch_size, max_sequence_length, self.num_heads * self.head_dim)\n",
        "        print(f\"values.size(): {values.size()}\")\n",
        "        out = self.linear_layer(values)\n",
        "        print(f\"out.size(): {out.size()}\")\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        print(f\"Mean ({mean.size()})\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        print(f\"Standard Deviation  ({std.size()})\")\n",
        "        y = (inputs - mean) / std\n",
        "        print(f\"y: {y.size()}\")\n",
        "        out = self.gamma * y  + self.beta\n",
        "        print(f\"self.gamma: {self.gamma.size()}, self.beta: {self.beta.size()}\")\n",
        "        print(f\"out: {out.size()}\")\n",
        "        return out\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        print(f\"x after first linear layer: {x.size()}\")\n",
        "        x = self.relu(x)\n",
        "        print(f\"x after activation: {x.size()}\")\n",
        "        x = self.dropout(x)\n",
        "        print(f\"x after dropout: {x.size()}\")\n",
        "        x = self.linear2(x)\n",
        "        print(f\"x after 2nd linear layer: {x.size()}\")\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads) #30x200x512\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual_x = x\n",
        "        print(\"------- ATTENTION 1 ------\")\n",
        "        x = self.attention(x, mask=None)\n",
        "        print(\"------- DROPOUT 1 ------\")\n",
        "        x = self.dropout1(x)\n",
        "        print(\"------- ADD AND LAYER NORMALIZATION 1 ------\")\n",
        "        x = self.norm1(x + residual_x)\n",
        "        residual_x = x\n",
        "        print(\"------- ATTENTION 2 ------\")\n",
        "        x = self.ffn(x)\n",
        "        print(\"------- DROPOUT 2 ------\")\n",
        "        x = self.dropout2(x)\n",
        "        print(\"------- ADD AND LAYER NORMALIZATION 2 ------\")\n",
        "        x = self.norm2(x + residual_x)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                     for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "TkKxONqmixON"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5\n",
        "\n",
        "encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)"
      ],
      "metadata": {
        "id": "aV4JdwmOxblm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn( (batch_size, max_sequence_length, d_model) ) # includes positional encoding\n",
        "print(x.shape)\n",
        "out = encoder(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "757_hG-HxboS",
        "outputId": "fdb6f736-78d4-4150-f7d3-088ac4896c2a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 1 ------\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv.size(): torch.Size([30, 200, 8, 192])\n",
            "qkv.size(): torch.Size([30, 8, 200, 192])\n",
            "q size: torch.Size([30, 8, 200, 64]), k size: torch.Size([30, 8, 200, 64]), v size: torch.Size([30, 8, 200, 64]), \n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values.size(): torch.Size([30, 8, 200, 64]), attention.size:torch.Size([30, 8, 200, 200]) \n",
            "values.size(): torch.Size([30, 200, 512])\n",
            "out.size(): torch.Size([30, 200, 512])\n",
            "------- DROPOUT 1 ------\n",
            "------- ADD AND LAYER NORMALIZATION 1 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "------- ATTENTION 2 ------\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after activation: torch.Size([30, 200, 2048])\n",
            "x after dropout: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "------- DROPOUT 2 ------\n",
            "------- ADD AND LAYER NORMALIZATION 2 ------\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "self.gamma: torch.Size([512]), self.beta: torch.Size([512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DECODER"
      ],
      "metadata": {
        "id": "WBhx8DXVXdtn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if input =30,200,512 30->batch,200->sequence max length 512->each token vector dim\n",
        "Position embedding layer jast add the dim of 200x512 to each batch to define the postional info of each token"
      ],
      "metadata": {
        "id": "DY1oW0cBYv3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    # q: 30 x 8 x 200 x 64, k: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64, mask 200 x 200\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k) # 30 x 8 x 200 x 200\n",
        "    print(f\"scaled.size() : {scaled.size()}\")\n",
        "    if mask is not None:\n",
        "        print(f\"-- ADDING MASK of shape {mask.size()} --\")\n",
        "        scaled += mask # 30 x 8 x 200 x 200\n",
        "    attention = F.softmax(scaled, dim=-1) # 30 x 8 x 200 x 200\n",
        "    values = torch.matmul(attention, v) # 30 x 8 x 200 x 64\n",
        "    return values, attention\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  x: 30 x 200 x 512\n",
        "        x = self.linear1(x) #30 x 200 x 2048\n",
        "        print(f\"x after first linear layer: {x.size()}\")\n",
        "        x = self.relu(x) #30 x 200 x 2048\n",
        "        print(f\"x after relu layer: {x.size()}\")\n",
        "        x = self.dropout(x) #30 x 200 x 2048\n",
        "        print(f\"x after dropout layer: {x.size()}\")\n",
        "        x = self.linear2(x) #30 x 200 x 512\n",
        "        print(f\"x after 2nd linear layer: {x.size()}\")\n",
        "        return x #30 x 200 x 512\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape)) # 512\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape)) # 512\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # inputs : 30 x 200 x 512\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))] # [-1]\n",
        "        print(f\"dims: {dims}\")\n",
        "        mean = inputs.mean(dim=dims, keepdim=True) #30 x 200 x 1\n",
        "        print(f\"Mean ({mean.size()})\")\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True) # 30 x 200 x 512\n",
        "        std = (var + self.eps).sqrt() # 30 x 200 x 512\n",
        "        print(f\"Standard Deviation  ({std.size()})\")\n",
        "        y = (inputs - mean) / std # 30 x 200 x 512\n",
        "        print(f\"y: {y.size()}\")\n",
        "        out = self.gamma * y  + self.beta  # 30 x 200 x 512\n",
        "        print(f\"out: {out.size()}\")\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model) # 1536\n",
        "        print(\"QKV\",self.qkv_layer)\n",
        "        #output qkv_layer->Linear(in_feture=512,out_feature=1536) all feature parameters of dim 1536 are\n",
        "        #trainable\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size() # 30 x 200 x 512\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        qkv = self.qkv_layer(x) # 30 x 200 x 1536\n",
        "        print(f\"qkv.size(): {qkv.size()}\")\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim) # 30 x 200 x 8 x 192\n",
        "        print(f\"qkv after reshape .size(): {qkv.size()}\")\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 192\n",
        "        print(f\"qkv after permutation: {qkv.size()}\")\n",
        "        q, k, v = qkv.chunk(3, dim=-1) # q: 30 x 8 x 200 x 64, k: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "        print(f\"q: {q.size()}, k:{k.size()}, v:{v.size()}\")\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) # values: 30 x 8 x 200 x 64\n",
        "        print(f\"values: {values.size()}, attention:{attention.size()}\")\n",
        "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim) # 30 x 200 x 512\n",
        "        print(f\"values after reshaping: {values.size()}\")\n",
        "        out = self.linear_layer(values) # 30 x 200 x 512\n",
        "        print(f\"out after passing through linear layer: {out.size()}\")\n",
        "        return out # 30 x 200 x 512\n",
        "\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model) # 1024\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        print(\"Qlayer\",self.q_layer)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask=None):\n",
        "        batch_size, sequence_length, d_model = x.size() # 30 x 200 x 512\n",
        "        print(f\"x.size(): {x.size()}\")\n",
        "        kv = self.kv_layer(x) # 30 x 200 x 1024\n",
        "        print(f\"kv.size(): {kv.size()}\")\n",
        "        q = self.q_layer(y) # 30 x 200 x 512\n",
        "        print(f\"q.size(): {q.size()}\")\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)  # 30 x 200 x 8 x 128\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)  # 30 x 200 x 8 x 64\n",
        "        kv = kv.permute(0, 2, 1, 3) # 30 x 8 x 200 x 128\n",
        "        q = q.permute(0, 2, 1, 3) # 30 x 8 x 200 x 64\n",
        "        k, v = kv.chunk(2, dim=-1) # K: 30 x 8 x 200 x 64, v: 30 x 8 x 200 x 64\n",
        "        values, attention = scaled_dot_product(q, k, v, mask) #  30 x 8 x 200 x 64\n",
        "        print(f\"values: {values.size()}, attention:{attention.size()}\")\n",
        "        values = values.reshape(batch_size, sequence_length, d_model) #  30 x 200 x 512\n",
        "        out = self.linear_layer(values)  #  30 x 200 x 512\n",
        "        print(f\"out after passing through linear layer: {out.size()}\")\n",
        "        return out  #  30 x 200 x 512\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, decoder_mask):\n",
        "        _y = y # 30 x 200 x 512\n",
        "        print(\"MASKED SELF ATTENTION\")\n",
        "        y = self.self_attention(y, mask=decoder_mask) # 30 x 200 x 512\n",
        "        print(\"DROP OUT 1\")\n",
        "        y = self.dropout1(y) # 30 x 200 x 512\n",
        "        print(\"ADD + LAYER NORMALIZATION 1\")\n",
        "        y = self.norm1(y + _y) # 30 x 200 x 512\n",
        "\n",
        "        _y = y # 30 x 200 x 512\n",
        "        print(\"CROSS ATTENTION\")\n",
        "        y = self.encoder_decoder_attention(x, y, mask=None) #30 x 200 x 512\n",
        "        print(\"DROP OUT 2\")  #30 x 200 x 512\n",
        "        y = self.dropout2(y)\n",
        "        print(\"ADD + LAYER NORMALIZATION 2\")\n",
        "        y = self.norm2(y + _y)  #30 x 200 x 512\n",
        "\n",
        "        _y = y  #30 x 200 x 512\n",
        "        print(\"FEED FORWARD 1\")\n",
        "        y = self.ffn(y) #30 x 200 x 512\n",
        "        print(\"DROP OUT 3\")\n",
        "        y = self.dropout3(y) #30 x 200 x 512\n",
        "        print(\"ADD + LAYER NORMALIZATION 3\")\n",
        "        y = self.norm3(y + _y) #30 x 200 x 512\n",
        "        return y #30 x 200 x 512\n",
        "\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, mask) #30 x 200 x 512\n",
        "        return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                          for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        #x : 30 x 200 x 512\n",
        "        #y : 30 x 200 x 512\n",
        "        #mask : 200 x 200\n",
        "        y = self.layers(x, y, mask)\n",
        "        return y #30 x 200 x 512\n",
        ""
      ],
      "metadata": {
        "id": "KL3cZqloxbq9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = 512\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "batch_size = 30\n",
        "max_sequence_length = 200\n",
        "ffn_hidden = 2048\n",
        "num_layers = 5\n",
        "\n",
        "x = torch.randn( (batch_size, max_sequence_length, d_model) ) # English sentence positional encoded\n",
        "y = torch.randn( (batch_size, max_sequence_length, d_model) ) # Kannada sentence positional encoded\n",
        "mask = torch.full([max_sequence_length, max_sequence_length] , float('-inf'))\n",
        "mask = torch.triu(mask, diagonal=1)\n",
        "decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers)\n",
        "out = decoder(x, y, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6cqJiBrXfmH",
        "outputId": "f3e56d04-a1aa-40ec-d91d-f7ecfb58af20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QKV Linear(in_features=512, out_features=1536, bias=True)\n",
            "Qlayer Linear(in_features=512, out_features=512, bias=True)\n",
            "QKV Linear(in_features=512, out_features=1536, bias=True)\n",
            "Qlayer Linear(in_features=512, out_features=512, bias=True)\n",
            "QKV Linear(in_features=512, out_features=1536, bias=True)\n",
            "Qlayer Linear(in_features=512, out_features=512, bias=True)\n",
            "QKV Linear(in_features=512, out_features=1536, bias=True)\n",
            "Qlayer Linear(in_features=512, out_features=512, bias=True)\n",
            "QKV Linear(in_features=512, out_features=1536, bias=True)\n",
            "Qlayer Linear(in_features=512, out_features=512, bias=True)\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "MASKED SELF ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "qkv.size(): torch.Size([30, 200, 1536])\n",
            "qkv after reshape .size(): torch.Size([30, 200, 8, 192])\n",
            "qkv after permutation: torch.Size([30, 8, 200, 192])\n",
            "q: torch.Size([30, 8, 200, 64]), k:torch.Size([30, 8, 200, 64]), v:torch.Size([30, 8, 200, 64])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "-- ADDING MASK of shape torch.Size([200, 200]) --\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "values after reshaping: torch.Size([30, 200, 512])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 1\n",
            "ADD + LAYER NORMALIZATION 1\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "CROSS ATTENTION\n",
            "x.size(): torch.Size([30, 200, 512])\n",
            "kv.size(): torch.Size([30, 200, 1024])\n",
            "q.size(): torch.Size([30, 200, 512])\n",
            "scaled.size() : torch.Size([30, 8, 200, 200])\n",
            "values: torch.Size([30, 8, 200, 64]), attention:torch.Size([30, 8, 200, 200])\n",
            "out after passing through linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 2\n",
            "ADD + LAYER NORMALIZATION 2\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n",
            "FEED FORWARD 1\n",
            "x after first linear layer: torch.Size([30, 200, 2048])\n",
            "x after relu layer: torch.Size([30, 200, 2048])\n",
            "x after dropout layer: torch.Size([30, 200, 2048])\n",
            "x after 2nd linear layer: torch.Size([30, 200, 512])\n",
            "DROP OUT 3\n",
            "ADD + LAYER NORMALIZATION 3\n",
            "dims: [-1]\n",
            "Mean (torch.Size([30, 200, 1]))\n",
            "Standard Deviation  (torch.Size([30, 200, 1]))\n",
            "y: torch.Size([30, 200, 512])\n",
            "out: torch.Size([30, 200, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Tokenization"
      ],
      "metadata": {
        "id": "jCKVgIgHh4Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        ""
      ],
      "metadata": {
        "id": "O5upv8WlXfpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_file = '/content/english.txt'\n",
        "kannada_file = '/content/kannada1.txt'\n",
        "\n",
        "START_TOKEN = ''\n",
        "PADDING_TOKEN = ''\n",
        "END_TOKEN = ''\n",
        "\n",
        "kannada_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', '',\n",
        "                      '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
        "                      '', '', '', '', '', '', '', '', '', '', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                        'Y', 'Z',\n",
        "\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        "\n"
      ],
      "metadata": {
        "id": "290OqW9cXfrc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "list(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV1h09UUxbtf",
        "outputId": "8daca14d-38f4-4d89-9d31-06e74d4d35a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '', '', '']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
        "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ],
      "metadata": {
        "id": "ANZn26iHi_GP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(kannada_file, 'r',encoding='utf-8') as file:\n",
        "    kannada_sentences = file.readlines()\n",
        "\n",
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 100\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n') for sentence in english_sentences]\n",
        "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
      ],
      "metadata": {
        "id": "VCyblsmQi_JF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kannada_sentences[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo-IIC-fi_ME",
        "outputId": "4568d8e2-20b6-4696-f197-4eae2242cf00"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  .',\n",
              " '\"        , \"\"     \"',\n",
              " ' 8  .']"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(kannada_sentences)):\n",
        "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5a7Z1pai_O7",
        "outputId": "4cc53d6b-e911-49a3-c9cc-d4de3321c206"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 100\n",
            "Number of valid sentences: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, kannada_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.kannada_sentences = kannada_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.kannada_sentences[idx]"
      ],
      "metadata": {
        "id": "GqbqyNZVj9LI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(english_sentences, kannada_sentences)\n",
        "print(len(dataset))\n",
        "\n",
        "print(dataset[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1OJHFLXj9ON",
        "outputId": "b17e9e34-f92a-41d2-85af-93283020fe2c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "(\"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\", '\"        , \"\"     \"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ],
      "metadata": {
        "id": "MbaltYfrj9R0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv-vQTu4j9Uj",
        "outputId": "d4a3554c-2bac-48f0-8c0a-e1311c35c41d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hes a scientist.', \"'But we speak the truth aur ye sach hai ke Gujarat mein vikas pagal hogaya hai,'' Rahul Gandhi further said in Banaskantha\", '8 lakh crore have been looted.'), ('  .', '\"        , \"\"     \"', ' 8  .')]\n",
            "[('I read a lot into this as well.', \"She was found dead with the phone's battery exploded close to her head the following morning.\", 'How did mankind come under Satans rival sovereignty?'), ('    .', '    \\u200c     .', '     ?')]\n",
            "[('And then I became Prime Minister.', 'What about corruption?', 'No differences'), ('   .', ' ?', ' ')]\n",
            "[('\"\"\"The shooting of the film is 90 percent done.\"', 'the Special Statute', '\"Then the king said to Ittai the Gittite, \"\"Why do you also go with us? Return, and stay with the king. for you are a foreigner, and also an exile. Return to your own place.\"'), ('   90    .', ' ', '    --    ?       .    .')]\n",
            "[('What happened at the UN General Assembly?', '720p HD recording', 'The meeting was attended by Prime Minister Narendra Modi, Home Minister Amit Shah and Defence Minister Rajnath Singh, among others.'), ('     ?', '   ', '   ,                    .')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
        "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
        "    if start_token:\n",
        "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
        "    if end_token:\n",
        "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
        "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
        "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
        "    return torch.tensor(sentence_word_indicies)\n",
        "\n",
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WXHvlUFj9XP",
        "outputId": "61fb8563-c3f6-46df-f86a-fdee6b9a3b66"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('What happened at the UN General Assembly?', '720p HD recording', 'The meeting was attended by Prime Minister Narendra Modi, Home Minister Amit Shah and Defence Minister Rajnath Singh, among others.'), ('     ?', '   ', '   ,                    .')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "ncwaflPZlf-w"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized, kn_tokenized = [], []\n",
        "for sentence_num in range(batch_size):\n",
        "    eng_sentence, kn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
        "    eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
        "    kn_tokenized.append( tokenize(kn_sentence, kannada_to_index, start_token=True, end_token=True) )\n",
        "eng_tokenized = torch.stack(eng_tokenized)\n",
        "kn_tokenized = torch.stack(kn_tokenized)"
      ],
      "metadata": {
        "id": "eSOLMgVOlgB9"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_tokenized"
      ],
      "metadata": {
        "id": "IB3qi79elgFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, kn_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
        "    print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ],
      "metadata": {
        "id": "F094K60OlgIV"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_masks(batch[0], batch[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoGB9_K2p5KI",
        "outputId": "663a8792-03f7-4fef-9b29-5cf41601bd80"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "decoder_self_attention_mask torch.Size([3, 200, 200]): tensor([[ 0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -1.0000e+09],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
            "decoder_cross_attention_mask torch.Size([3, 200, 200]): tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]),\n",
              " tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]],\n",
              " \n",
              "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          ...,\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -1.0000e+09, -1.0000e+09,  ..., -1.0000e+09,\n",
              "           -1.0000e+09, -1.0000e+09]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}